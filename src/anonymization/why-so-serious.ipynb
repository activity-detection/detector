{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc43d8814f449fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import shutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9b06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = \"C:/Users/Mateusz/Nextcloud/Projekty/projekt-grupowy/detector/\"\n",
    "data_loc = base_loc + \"/data/final_yolopose_dataset/data.yaml\"\n",
    "models_loc = base_loc + \"/models/runs/detect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8931ccddeaf4fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.241 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.227  Python-3.12.12 torch-2.9.0+cu130 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:/Users/Mateusz/Nextcloud/Projekty/projekt-grupowy/detector//data/final_yolopose_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:/Users/Mateusz/Nextcloud/Projekty/projekt-grupowy/detector/models/yolo11x-pose.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train18, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:/Users/Mateusz/Nextcloud/Projekty/projekt-grupowy/detector//models/runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\models\\runs\\detect\\train18, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
      " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
      " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
      " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
      " 23        [16, 19, 22]  1   5071567  ultralytics.nn.modules.head.Pose             [2, [17, 3], [384, 768, 768]] \n",
      "YOLO11x-pose summary: 372 layers, 58,799,791 parameters, 58,799,775 gradients, 203.8 GFLOPs\n",
      "\n",
      "Transferred 1051/1057 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 824.2609.3 MB/s, size: 83.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\labels\\train.cache... 14057 images, 5 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 14057/14057  0.0s\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (13.6GB Disk): 100% ━━━━━━━━━━━━ 14057/14057 27.4Kit/s 0.5s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 293.5233.4 MB/s, size: 22.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\labels\\val.cache... 4223 images, 3 backgrounds, 18 corrupt: 100% ━━━━━━━━━━━━ 4241/4241  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000038118.jpg: ignoring corrupt image/label: image file is truncated (25 bytes not processed)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000038210.jpg: ignoring corrupt image/label: image file is truncated (9 bytes not processed)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000038678.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000038678.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000038829.jpg: ignoring corrupt image/label: image file is truncated (60 bytes not processed)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000039405.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000039405.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000039480.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000039480.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000039484.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000039484.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000039785.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000039785.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000121242.jpg: ignoring corrupt image/label: image file is truncated (70 bytes not processed)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000121497.jpg: ignoring corrupt image/label: image file is truncated (13 bytes not processed)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000121744.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000121744.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000122046.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000122046.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000122166.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000122166.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000122217.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000122217.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000122606.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000122606.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000122672.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000122672.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000122962.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000122962.jpg'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\data\\final_yolopose_dataset\\images\\val\\000000123480.jpg: ignoring corrupt image/label: cannot identify image file 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\data\\\\final_yolopose_dataset\\\\images\\\\val\\\\000000123480.jpg'\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.7GB Disk): 100% ━━━━━━━━━━━━ 4223/4223 33.8Kit/s 0.1s.2s\n",
      "Plotting labels to C:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\models\\runs\\detect\\train18\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 173 weight(decay=0.0), 183 weight(decay=0.0005), 182 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\models\\runs\\detect\\train18\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/10      8.22G      1.675      4.796     0.4966      1.863      1.655          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.2it/s 7:03<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 5.7it/s 46.4s<0.1s\n",
      "                   all       4223      11110      0.576       0.51      0.512      0.284     0.0693     0.0423     0.0158    0.00317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/10      8.84G      1.742      5.288     0.4934      1.754       1.71          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.5it/s 6:33<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 6.8it/s 38.5s<0.1s\n",
      "                   all       4223      11110      0.627      0.536      0.565      0.315      0.114     0.0568     0.0303    0.00702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/10       8.5G      1.642      5.112     0.4296      1.613      1.638          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.5it/s 6:27<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 6.9it/s 38.1s<0.1s\n",
      "                   all       4223      11110      0.728      0.571      0.624      0.373      0.153     0.0735     0.0495     0.0121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/10      8.99G      1.549      4.918     0.4015      1.467      1.564          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.6it/s 6:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 7.0it/s 38.0s<0.1s\n",
      "                   all       4223      11110      0.756      0.625      0.683      0.409      0.186      0.095     0.0718     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/10      9.02G       1.47      4.659     0.3701      1.345      1.505          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.6it/s 6:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 6.9it/s 38.2s<0.1s\n",
      "                   all       4223      11110       0.76      0.655      0.708      0.441      0.192      0.114     0.0788     0.0243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/10      9.02G        1.4      4.464     0.3473      1.245      1.455          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.6it/s 6:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 6.9it/s 38.1s<0.1s\n",
      "                   all       4223      11110      0.773      0.684      0.737       0.47      0.223      0.125      0.102     0.0322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/10      9.03G      1.352       4.37     0.3246       1.16      1.419          3        640: 100% ━━━━━━━━━━━━ 1758/1758 4.6it/s 6:23<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 7.0it/s 37.9s<0.1s\n",
      "                   all       4223      11110      0.793        0.7      0.753      0.485      0.231      0.134      0.103     0.0338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/10      9.02G      1.308      4.208      0.307      1.091       1.38          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.6it/s 6:24<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 7.0it/s 38.0s<0.1s\n",
      "                   all       4223      11110      0.798      0.711      0.762      0.498      0.228      0.141      0.115     0.0407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/10      9.03G      1.256      4.098     0.2992      1.037      1.353          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.4it/s 6:36<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 6.4it/s 41.1s<0.2s\n",
      "                   all       4223      11110      0.794      0.726      0.777      0.514       0.26      0.152      0.136     0.0509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/10      9.02G      1.218      3.973     0.2751     0.9729      1.316          1        640: 100% ━━━━━━━━━━━━ 1758/1758 4.4it/s 6:40<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 6.6it/s 39.9s<0.2s\n",
      "                   all       4223      11110      0.819       0.74      0.793      0.529      0.267       0.16      0.142     0.0551\n",
      "\n",
      "10 epochs completed in 1.206 hours.\n",
      "Optimizer stripped from C:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\models\\runs\\detect\\train18\\weights\\last.pt, 118.2MB\n",
      "Optimizer stripped from C:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\models\\runs\\detect\\train18\\weights\\best.pt, 118.2MB\n",
      "\n",
      "Validating C:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\models\\runs\\detect\\train18\\weights\\best.pt...\n",
      "Ultralytics 8.3.227  Python-3.12.12 torch-2.9.0+cu130 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLO11x-pose summary (fused): 199 layers, 58,752,463 parameters, 0 gradients, 202.8 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 264/264 6.8it/s 38.9s<0.1s\n",
      "                   all       4223      11110      0.821      0.738      0.793      0.529      0.268       0.16      0.142     0.0551\n",
      "                person       2175       8915      0.699      0.566      0.639      0.399      0.535       0.32      0.284       0.11\n",
      "         license_plate       2045       2195      0.943       0.91      0.946      0.659          0          0          0          0\n",
      "Speed: 0.1ms preprocess, 5.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\Mateusz\\Nextcloud\\Projekty\\projekt-grupowy\\detector\\models\\runs\\detect\\train18\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(base_loc+\"models/yolo11x-pose.pt\")\n",
    "\n",
    "results = model.train(\n",
    "    data=data_loc,\n",
    "    epochs=10,\n",
    "    imgsz=640,\n",
    "    device=0,\n",
    "    project=models_loc,\n",
    "    \n",
    "    # --- OPTYMALIZACJA ---\n",
    "    batch=8,       \n",
    "    \n",
    "    workers=8,   \n",
    "    \n",
    "    cache='disk',     # Największe przyspieszenie: trzymaj zdjęcia w RAM (jeśli masz RAM)\n",
    "                    # Jeśli brakuje RAM, użyj cache='disk' (szybciej niż brak cache)\n",
    "    \n",
    "    amp=True,       # Mixed Precision (szybsze obliczenia na GPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4a3104",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\models\\\\runs\\\\detect\\\\train9\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_loc\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/models/runs/detect/train9/weights/best.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m results = model(base_loc+\u001b[33m\"\u001b[39m\u001b[33m/data/License-Plate-Recognition-11/test/images/00a7d31c6cc6b7f3_jpg.rf.641695200cda83be76f64c5402215f27.jpg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m results[\u001b[32m0\u001b[39m].show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:81\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\ultralytics\\engine\\model.py:149\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\ultralytics\\engine\\model.py:288\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    285\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1461\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_checkpoint\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1449\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a single model weights.\u001b[39;00m\n\u001b[32m   1450\u001b[39m \n\u001b[32m   1451\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1459\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1462\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1463\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1409\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1407\u001b[39m                 ckpt = torch_load(f, pickle_module=safe_pickle)\n\u001b[32m   1408\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1409\u001b[39m             ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\ultralytics\\utils\\patches.py:116\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    114\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\torch\\serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Mateusz\\miniforge3\\envs\\projekt_grupowy\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Mateusz\\\\Nextcloud\\\\Projekty\\\\projekt-grupowy\\\\detector\\\\models\\\\runs\\\\detect\\\\train9\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "model = YOLO(base_loc+\"/models/runs/detect/train9/weights/best.pt\")\n",
    "results = model(base_loc+\"/data/License-Plate-Recognition-11/test/images/00a7d31c6cc6b7f3_jpg.rf.641695200cda83be76f64c5402215f27.jpg\")\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b88326",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Projects\\\\Python\\\\VSCode\\\\anonymizationmodels\\\\runs\\\\detect\\\\train9\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_loc\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mruns\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mdetect\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mtrain9\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mweights\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[33;43mbest.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m results = model(\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mProjects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mPython\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mVSCode\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33manonymization\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mpolen17.jpg\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m results[\u001b[32m0\u001b[39m].show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:76\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\ultralytics\\engine\\model.py:144\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\ultralytics\\engine\\model.py:283\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    280\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1461\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_checkpoint\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1449\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a single model weights.\u001b[39;00m\n\u001b[32m   1450\u001b[39m \n\u001b[32m   1451\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1459\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1462\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1463\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1409\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1407\u001b[39m                 ckpt = torch_load(f, pickle_module=safe_pickle)\n\u001b[32m   1408\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1409\u001b[39m             ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\ultralytics\\utils\\patches.py:116\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    114\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\Python\\VSCode\\anonymization\\.pixi\\envs\\default\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Projects\\\\Python\\\\VSCode\\\\anonymizationmodels\\\\runs\\\\detect\\\\train9\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "model = YOLO(base_loc+\"models\\\\runs\\\\detect\\\\train\\\\weights\\\\best.pt\")\n",
    "results = model(\"C:\\\\Projects\\\\Python\\\\VSCode\\\\anonymization\\\\data\\\\polen17.jpg\")\n",
    "results[0].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projekt_grupowy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
